<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 二木的博客</title>
    <link>https://zhuermu.github.io/posts/</link>
    <description>Recent content in Posts on 二木的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 20 Nov 2022 09:03:20 -0800</lastBuildDate><atom:link href="https://zhuermu.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HTTP协议路由转发小结</title>
      <link>https://zhuermu.github.io/posts/2023-02-10-http-router-transfer/</link>
      <pubDate>Sun, 20 Nov 2022 09:03:20 -0800</pubDate>
      
      <guid>https://zhuermu.github.io/posts/2023-02-10-http-router-transfer/</guid>
      <description>hosts指向里约网关IP，但最终访问到应用了 问题介绍：个人电脑 hosts 文件配置如下：
xx.xx.xx.243 xxx.domain.com
其中 xx.xx.xx.243 是里约网关的服务器ip，而应用部署在 xx.xx.xx.93 上，但最终请求为何会转发到93这台服务器上呢？
原因是里约网关配置了转发规则，当网关接收到的请求host是 xxx.domain.com 时，就将请求转发到 93 这台服务器上。这种就是典型的HTTP(7层)转发规则，对应的有TCP(4层)转发，感兴趣的可以了解对比下。那网关是如何转发请求的呢？
先从HTTP协议说起 就以我们政务开放平台系统为例说明，上述条件依旧成立即：里约部署在243服务器上，开放平台部署在93上，我本地开发机配置hosts:
xx.xx.xx.243 xxx.domain.com
浏览器访问 http://xxx1.domain.com/api/corp/personal/user_info，我们先用Wireshark抓包看下http请求(注意抓包时，选择wifi网卡，设置条件 http &amp;amp;&amp;amp; ip.addr == xx.xx.xx.243过滤）。下面是我的抓包内容。
GET /api/corp/personal/user_info HTTP/1.1 #请求方法 PATH路径 http版本号 Host: xxx.domain.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: en,zh-CN;q=0.9,zh;q=0.8,zh-TW;q=0.7,und;q=0.6 HTTP/1.1 200 OK # 版本号 返回状态码 对应信息 x-proxy-by: Tif-accessgate Date: Fri, 04 Dec 2020 11:56:17 GMT Content-Type: application/json; charset=utf-8 Content-Length: 357 Connection: keep-alive Reqid: UMMIoNR7NfTQfCBeqY9E x-forwarded-for: 9.</description>
    </item>
    
    <item>
      <title>一次cpu使用率低负载高的生产事故</title>
      <link>https://zhuermu.github.io/posts/2019-09-24-record-a-production-accident/</link>
      <pubDate>Sun, 20 Nov 2022 09:03:20 -0800</pubDate>
      
      <guid>https://zhuermu.github.io/posts/2019-09-24-record-a-production-accident/</guid>
      <description>Introduction 事故背景 昨天晚上半夜3：26分被电话铃声吵醒了，看到一个未接电话，然后看到微信里面同事拉了群，看到是我负责的一个服务分布式文件存储系统报警了， 报警信息是部署该服务的所有机器同时出现了load average,并且运维同事已经尝试重启应用来恢复负载过高问题，依然无效，重启应用之后服务器负载又马上飙山来。
处理过程 由于我刚刚入职该公司，接手这个文件存储系统不到2个礼拜，而之前开发的人都离职了。这个系统非常重要，整个公司的所有的涉及到文件存储的应用都是接入该服务，一旦出现故障将会影响全站的服务，因此，必须在天亮前回复服务器压力，避免影响白天应用对外的服务。这个时候我感到一股前所未有的压力，我一下清醒了，考虑到在家里没有生产权限，只能和运维配置一起排查问题，我按时间顺序大概做了这么几件事：
上监控系统查看是否又报错日志，排查系统报错导致的负载； 找运维查看jvm的gc日志，排查是否存在异常的gc； 找运维执行 jstack -l pid 查看应用是否存在异常的线程堆栈信息。 运维给出了top截图，看当前服务器资源使用和进程的情况 1~3 都正常，top命令看到 load average w1 w5 w15 都达到10以上，cpu只用了不到1%，看上去是一个cpu低，负载高的问题，因为程序既没有出错，运行状态看上去也正常感觉负载高可能不是应用本身造成。
让运维看下磁盘容量：由于该系统是文件存储系统，因此我们怀疑下是否由于磁盘满了导致了负载过高呢？ 在运维执行 df -h 命令时一直卡住无法出结果，感觉可能和磁盘有关系，部署文件存储系统的服务器都挂载了NAS存储设备，于是开始联系负责NAS服务的运维，发现有个NAS服务挂掉了，重启NAS服务之后，重新挂载NAS盘，系统开始恢复。
分析总结 本次问题的根本原因是NAS所在的宿主物理机发现宕机，导致虚拟机的NAS服务重启，重启后该应用（nfs）没有设置开机自启动，进而导致了文件存储系统所在的机器连接挂载的存储设备，因此文件存储服务无法读写该设备，造成了IO等待的过高的负载。 最后大家可以看下该文章的分析，我们的情况在他的分析之中。cpu使用率低负载高，原因分析</description>
    </item>
    
    <item>
      <title>《Java并发编程实战》小结</title>
      <link>https://zhuermu.github.io/posts/2017-03-06-java-concurrent-summary/</link>
      <pubDate>Mon, 06 Mar 2017 09:03:20 -0800</pubDate>
      
      <guid>https://zhuermu.github.io/posts/2017-03-06-java-concurrent-summary/</guid>
      <description>##背景 前段时间想更深入了解下Java多线程相关的知识，对Java多线程有一个全面的认识，所以想找一本Java多线程相关的书籍来阅读，最后我选择了《Java并发编程实战》这本个人认为还算相当不错，至于为什么选择它，下面有介绍。
##书的介绍 中文书名：《Java并发编程实战》 英文书名：《Java Concurrency in Practice》 作者：Brian Goetz / Tim Peierls / Joshua Bloch / Joseph Bowbeer / David Holmes / Doug Lea 译者：童云兰 出版社: 机械工业出版社华章公司 购买可以在各大电商网站搜索书名购买，请支持正版 ##选择该书原因 1、亚马逊排名考前，评论多评分也不错； 2、很多java程序员必看数据整理里面的书单之一； 3、豆瓣评分9.0； 4、作者都很牛B。
##图书简介 《Java并发编程实战》深入浅出地介绍了Java线程和并发,是一本完美的Java并发参考手册。书中从并发性和线程安全性的基本概念出发,介绍了如何使用类库提供的基本并发构建块,用于避免并发危险、 构造线程安全的类及验证线程安全的规则,如何将小的线程安全类组合成更大的线程安全类,如何利用线程来提高并发应用程序的吞吐量,如何识别可并行执行的任务,如何提高单线程子系统的响应性,如 何确保并发程序执行预期任务,如何提高并发代码的性能和可伸缩性等内容,最后介绍了一些高级主题,如显式锁、原子变量、非阻塞算法以及如何开发自定义的同步工具类。 《Java并发编程实战》适合Java程序开发人员阅读。
##作者简介 本书作者都是Java Community Process JSR 166专家组（并发工具）的主要成员，并在其他很多JCP专家组里任职。Brian Goetz有20多年的软件咨询行业经验，并著有至少75篇关于Java开发的文章。 Tim Peierls是“现代多处理器”的典范，他在BoxPop.biz、唱片艺术和戏剧表演方面也颇有研究。Joseph Bowbeer是一个Java ME专家，他对并发编程的兴趣始于Apollo计算机时代。David Holmes是 《The Java Programming Language》一书的合著者，任职于Sun公司。Joshua Bloch是Google公司的首席Java架构师，《Effective Java》一书的作者，并参与著作了《Java Puzzlers》。Doug Lea 是《Concurrent Programming》一书的作者，纽约州立大学 Oswego分校的计算机科学教授。 备注：缩写的解释如下
Java Community Process（JCP） wiki 英文介绍 wiki 中文介绍 Java Specification Requests（JSR） ##一些需要提前掌握的基础 ###进程与线程 进程与线程的解释 ###线程 &amp;amp; 进程 &amp;amp; 服务器硬件之间的关系 总核数 = 物理CPU个数 X 每颗物理CPU的核数 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。 但同一进程中的多个线程有各自的调用栈（call stack），自己的寄存器环境（register context），自己的线程本地存储（thread-local storage）。 大量用户线程复用少量的轻权进程（内核线程）进程才是程序（那些指令和数据）的真正运行实例。若干进程有可能与同一个程序相关系，且每个进程皆可以同步（循序）或异步（平行）的方式独立运行。</description>
    </item>
    
  </channel>
</rss>
